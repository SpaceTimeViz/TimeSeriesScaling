{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## NYISO Load Prediction - Smoothing Kernel\n",
    "- Objective: Utilize the NBEATS model to predict NYISO load data for 2023-12-31 using historical data from 2013-01-01 to 2023-12-30.\n",
    "- Zones: `N.Y.C.`, `NORTH`, `CENTRL`\n",
    "- Scaling methods: [definition](https://nixtlaverse.nixtla.io/neuralforecast/common.scalers.html)\n",
    "     - [`identity`](https://nixtlaverse.nixtla.io/neuralforecast/common.scalers.html#std-statistics)\n",
    "     - `revin`:  learnable normalization parameters are added on top of the usual normalization technique.\n",
    "     - `smoothing`: Apply Gaussian kernel smoothing with window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pickle\n",
    "import logging\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from bokeh.models import ColumnDataSource, Select, CustomJS, DatetimeTickFormatter\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import Category10\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import HBox, VBox\n",
    "from ipywidgets.embed import embed_minimal_html\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalizer:\n",
    "    def __init__(self, window_size=7, sigma=2):\n",
    "        \"\"\"\n",
    "        Initialize the normalizer with kernel smoothing parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - window_size: The size of the window for rolling standard deviation.\n",
    "        - sigma: The standard deviation for Gaussian kernel smoothing.\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.sigma = sigma\n",
    "        self.smoothed_y = None\n",
    "        self.std_y = None\n",
    "\n",
    "    def fit(self, y):\n",
    "        # Fill NaN values before fitting\n",
    "        y = pd.Series(y).fillna(method='ffill').fillna(method='bfill').values\n",
    "        \n",
    "        # Apply Gaussian kernel smoothing\n",
    "        self.smoothed_y = gaussian_filter1d(y, sigma=self.sigma)\n",
    "        \n",
    "        # Calculate rolling standard deviation\n",
    "        self.std_y = pd.Series(y).rolling(window=self.window_size, min_periods=1).std().fillna(method='bfill').values\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, y):\n",
    "        # Fill NaN values before transforming\n",
    "        y = pd.Series(y).fillna(method='ffill').fillna(method='bfill').values\n",
    "        \n",
    "        if self.smoothed_y is None or self.std_y is None:\n",
    "            raise RuntimeError(\"The normalizer must be fitted before calling transform.\")\n",
    "        \n",
    "        smoothed_y_partial = self.smoothed_y[-len(y):]\n",
    "        std_y_partial = self.std_y[-len(y):]\n",
    "\n",
    "        # Handle any NaN or zero values in std_y_partial to avoid extreme values\n",
    "        std_y_partial = np.where(np.isnan(std_y_partial) | (std_y_partial == 0), 1e-6, std_y_partial)\n",
    "        \n",
    "        normalized_y = (y - smoothed_y_partial) / std_y_partial\n",
    "\n",
    "        # Forward-fill any remaining NaN values in normalized_y\n",
    "        normalized_y = pd.Series(normalized_y).fillna(method='ffill').values\n",
    "        \n",
    "        return normalized_y\n",
    "\n",
    "    def fit_transform(self, y):\n",
    "        self.fit(y)\n",
    "        return self.transform(y)\n",
    "\n",
    "    def inverse_transform(self, normalized_y):\n",
    "        if self.smoothed_y is None or self.std_y is None:\n",
    "            raise RuntimeError(\"The normalizer must be fitted before calling inverse_transform.\")\n",
    "        \n",
    "        smoothed_y_partial = self.smoothed_y[-len(normalized_y):]\n",
    "        std_y_partial = self.std_y[-len(normalized_y):]\n",
    "        \n",
    "        denormalized_y = normalized_y * std_y_partial + smoothed_y_partial\n",
    "        return denormalized_y\n",
    "\n",
    "\n",
    "def calculate_overall_mse(zone_dfs, true_col='y', prediction_cols=['NBEATS - Identity', 'NBEATS - Reinv', 'NBEATS - Smoothing']):\n",
    "    mse_results = {col: [] for col in prediction_cols}\n",
    "    traning_len = len(zone_dfs)\n",
    "\n",
    "    # Loop through all the DataFrames in the list\n",
    "    for df in zone_dfs:\n",
    "        # Ensure the DataFrame is properly formatted and named\n",
    "        df = df.rename(columns={'NBEATS1': 'NBEATS - Reinv'})\n",
    "        \n",
    "        # Drop rows with NaN values in any of the relevant columns\n",
    "        df = df.dropna(subset=[true_col] + prediction_cols)\n",
    "        \n",
    "        y_true = df[true_col].iloc[-24:]\n",
    "        \n",
    "        for col in prediction_cols:\n",
    "            mse = mean_squared_error(y_true, df[col].iloc[-24:])\n",
    "            mse_results[col].append(mse)\n",
    "    \n",
    "    #return {col: (np.mean(mse_results[col]), np.std(mse_results[col])/np.sqrt(traning_len)) for col in prediction_cols}\n",
    "    return {col: round(np.mean(mse_results[col]), 3) for col in prediction_cols}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from pickle files successfully.\n"
     ]
    }
   ],
   "source": [
    "with open('all_prediction_dfs.pkl', 'rb') as f:\n",
    "    all_prediction_dfs = pickle.load(f)\n",
    "\n",
    "print(\"Data loaded from pickle files successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CAPITL</th>\n",
       "      <th>CENTRL</th>\n",
       "      <th>DUNWOD</th>\n",
       "      <th>GENESE</th>\n",
       "      <th>HUD VL</th>\n",
       "      <th>LONGIL</th>\n",
       "      <th>MHK VL</th>\n",
       "      <th>MILLWD</th>\n",
       "      <th>N.Y.C.</th>\n",
       "      <th>NORTH</th>\n",
       "      <th>WEST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NBEATS - Identity</th>\n",
       "      <td>8201.244</td>\n",
       "      <td>13962.623</td>\n",
       "      <td>3854.546</td>\n",
       "      <td>6475.610</td>\n",
       "      <td>10805.418</td>\n",
       "      <td>58922.204</td>\n",
       "      <td>3340.392</td>\n",
       "      <td>1332.667</td>\n",
       "      <td>120901.085</td>\n",
       "      <td>555.585</td>\n",
       "      <td>9837.963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NBEATS - Reinv</th>\n",
       "      <td>8060.273</td>\n",
       "      <td>16798.849</td>\n",
       "      <td>4247.082</td>\n",
       "      <td>7154.422</td>\n",
       "      <td>11444.606</td>\n",
       "      <td>50559.936</td>\n",
       "      <td>3763.228</td>\n",
       "      <td>1720.273</td>\n",
       "      <td>144643.707</td>\n",
       "      <td>694.176</td>\n",
       "      <td>9051.257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NBEATS - Smoothing</th>\n",
       "      <td>11067.333</td>\n",
       "      <td>23723.661</td>\n",
       "      <td>6526.208</td>\n",
       "      <td>8508.908</td>\n",
       "      <td>10661.199</td>\n",
       "      <td>64729.461</td>\n",
       "      <td>5617.927</td>\n",
       "      <td>1598.675</td>\n",
       "      <td>284407.097</td>\n",
       "      <td>720.592</td>\n",
       "      <td>12948.159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       CAPITL     CENTRL    DUNWOD    GENESE     HUD VL  \\\n",
       "NBEATS - Identity    8201.244  13962.623  3854.546  6475.610  10805.418   \n",
       "NBEATS - Reinv       8060.273  16798.849  4247.082  7154.422  11444.606   \n",
       "NBEATS - Smoothing  11067.333  23723.661  6526.208  8508.908  10661.199   \n",
       "\n",
       "                       LONGIL    MHK VL    MILLWD      N.Y.C.    NORTH  \\\n",
       "NBEATS - Identity   58922.204  3340.392  1332.667  120901.085  555.585   \n",
       "NBEATS - Reinv      50559.936  3763.228  1720.273  144643.707  694.176   \n",
       "NBEATS - Smoothing  64729.461  5617.927  1598.675  284407.097  720.592   \n",
       "\n",
       "                         WEST  \n",
       "NBEATS - Identity    9837.963  \n",
       "NBEATS - Reinv       9051.257  \n",
       "NBEATS - Smoothing  12948.159  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming all_prediction_dfs is a dictionary where each key is a zone name and the value is a list of DataFrames\n",
    "results = pd.DataFrame({zone: calculate_overall_mse(zone_dfs) for zone, zone_dfs in all_prediction_dfs.items()})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0036db837db64ecda40ad5c96dd419d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Select Zone:', options=('CAPITL', 'CENTRL', 'DUNWOD', 'GENESE', 'HUD VL',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assume all_prediction_dfs is a dictionary where keys are zones and values are DataFrames\n",
    "initial_zone = zones[0]\n",
    "initial_sample_index = 0\n",
    "\n",
    "output_prediction = widgets.Output()\n",
    "\n",
    "def update_plot(change=None):\n",
    "    selected_zone = dropdown_zone.value\n",
    "    selected_sample_index = dropdown_sample_index.value\n",
    "    \n",
    "    # Update prediction plot\n",
    "    with output_prediction:\n",
    "        clear_output(wait=True)\n",
    "        plot_df = all_prediction_dfs[selected_zone][selected_sample_index].drop(\"ds\", axis=1).iloc[-168:].drop(\"unique_id\", axis=1)\n",
    "        fig_prediction = plot_prediction(plot_df, selected_zone)\n",
    "        show(fig_prediction, notebook_handle=True)\n",
    "\n",
    "# Dropdown for selecting zone\n",
    "dropdown_zone = widgets.Dropdown(\n",
    "    options=zones,\n",
    "    value=initial_zone,\n",
    "    description='Select Zone:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "dropdown_zone.observe(update_plot, names='value')\n",
    "\n",
    "# Dropdown for selecting sample index\n",
    "sample_indices = list(range(len(all_prediction_dfs[initial_zone])))\n",
    "dropdown_sample_index = widgets.Dropdown(\n",
    "    options=sample_indices,\n",
    "    value=initial_sample_index,\n",
    "    description='Select Sample Index:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "dropdown_sample_index.observe(update_plot, names='value')\n",
    "\n",
    "layout = widgets.VBox([dropdown_zone, dropdown_sample_index, output_prediction])\n",
    "\n",
    "display(layout)\n",
    "update_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts-scaler",
   "language": "python",
   "name": "ts-scaler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
