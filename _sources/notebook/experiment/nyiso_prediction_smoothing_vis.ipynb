{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "## NYISO Load Prediction - Gaussian Kernel\n",
    "- Objective: Utilize the NBEATS model to predict NYISO load data using historical data from 2013-01-01 to 2023-12-30.\n",
    "- Training Scheme\n",
    "    - Random Sampling: For each sample, randomly select a date and use the 24 time steps (hours) as test data. The preceding 200 days are used as training data.\n",
    "    - Repetition: Sample 100 unique pairs of training and test datasets.\n",
    "    - Scaling and Prediction: Apply scaling methods on the training data, train the NBEATS model, and then use it to generate predictions for the test data.\n",
    "- Scaling methods: [definition](https://nixtlaverse.nixtla.io/neuralforecast/common.scalers.html)\n",
    "     - [`identity`](https://nixtlaverse.nixtla.io/neuralforecast/common.scalers.html#std-statistics)\n",
    "     - `revin`:  learnable normalization parameters are added on top of the usual normalization technique.\n",
    "     - `smoothing`: Apply Gaussian kernel with $\\sigma =  448$"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pickle\n",
    "import warnings\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from IPython.display import display, clear_output\n",
    "from bokeh.models import ColumnDataSource, DatetimeTickFormatter\n",
    "from bokeh.palettes import Category10\n",
    "from bokeh.plotting import figure, show, output_notebook\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Normalizer:\n",
    "    def __init__(self, window_size=7, sigma=2):\n",
    "        \"\"\"\n",
    "        Initialize the normalizer with kernel smoothing parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        - window_size: The size of the window for rolling standard deviation.\n",
    "        - sigma: The standard deviation for Gaussian kernel smoothing.\n",
    "        \"\"\"\n",
    "        self.window_size = window_size\n",
    "        self.sigma = sigma\n",
    "        self.smoothed_y = None\n",
    "        self.std_y = None\n",
    "\n",
    "    def fit(self, y):\n",
    "        # Fill NaN values before fitting\n",
    "        y = pd.Series(y).fillna(method='ffill').fillna(method='bfill').values\n",
    "\n",
    "        # Apply Gaussian kernel smoothing\n",
    "        self.smoothed_y = gaussian_filter1d(y, sigma=self.sigma)\n",
    "\n",
    "        # Calculate rolling standard deviation\n",
    "        self.std_y = pd.Series(y).rolling(window=self.window_size, min_periods=1).std().fillna(method='bfill').values\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, y):\n",
    "        # Fill NaN values before transforming\n",
    "        y = pd.Series(y).fillna(method='ffill').fillna(method='bfill').values\n",
    "\n",
    "        if self.smoothed_y is None or self.std_y is None:\n",
    "            raise RuntimeError(\"The normalizer must be fitted before calling transform.\")\n",
    "\n",
    "        smoothed_y_partial = self.smoothed_y[-len(y):]\n",
    "        std_y_partial = self.std_y[-len(y):]\n",
    "\n",
    "        # Handle any NaN or zero values in std_y_partial to avoid extreme values\n",
    "        std_y_partial = np.where(np.isnan(std_y_partial) | (std_y_partial == 0), 1e-6, std_y_partial)\n",
    "\n",
    "        normalized_y = (y - smoothed_y_partial) / std_y_partial\n",
    "\n",
    "        # Forward-fill any remaining NaN values in normalized_y\n",
    "        normalized_y = pd.Series(normalized_y).fillna(method='ffill').values\n",
    "\n",
    "        return normalized_y\n",
    "\n",
    "    def fit_transform(self, y):\n",
    "        self.fit(y)\n",
    "        return self.transform(y)\n",
    "\n",
    "    def inverse_transform(self, normalized_y):\n",
    "        if self.smoothed_y is None or self.std_y is None:\n",
    "            raise RuntimeError(\"The normalizer must be fitted before calling inverse_transform.\")\n",
    "\n",
    "        smoothed_y_partial = self.smoothed_y[-len(normalized_y):]\n",
    "        std_y_partial = self.std_y[-len(normalized_y):]\n",
    "\n",
    "        denormalized_y = normalized_y * std_y_partial + smoothed_y_partial\n",
    "        return denormalized_y\n",
    "\n",
    "\n",
    "def calculate_overall_mse(zone_dfs, true_col='y',\n",
    "                          prediction_cols=['NBEATS - Identity', 'NBEATS - Reinv', 'NBEATS - Smoothing']):\n",
    "    mse_results = {col: [] for col in prediction_cols}\n",
    "    traning_len = len(zone_dfs)\n",
    "\n",
    "    # Loop through all the DataFrames in the list\n",
    "    for df in zone_dfs:\n",
    "        # Ensure the DataFrame is properly formatted and named\n",
    "        df = df.rename(columns={'NBEATS1': 'NBEATS - Reinv'})\n",
    "\n",
    "        # Drop rows with NaN values in any of the relevant columns\n",
    "        df = df.dropna(subset=[true_col] + prediction_cols)\n",
    "\n",
    "        y_true = df[true_col].iloc[-24:]\n",
    "\n",
    "        for col in prediction_cols:\n",
    "            mse = mean_squared_error(y_true, df[col].iloc[-24:])\n",
    "            mse_results[col].append(mse)\n",
    "\n",
    "    #return {col: (np.mean(mse_results[col]), np.std(mse_results[col])/np.sqrt(traning_len)) for col in prediction_cols}\n",
    "    return {col: round(np.mean(mse_results[col]), 3) for col in prediction_cols}\n",
    "\n",
    "\n",
    "def calculate_mse(y_true, y_pred):\n",
    "    return mean_squared_error(y_true[-24:], y_pred[-24:])\n",
    "\n",
    "\n",
    "def plot_prediction(plot_df, zone):\n",
    "    # Rename the column for consistency\n",
    "    plot_df = plot_df.rename(columns={\n",
    "        'NBEATS1': 'NBEATS - Reinv',  # Corrected to 'Reinv' to match the previous context\n",
    "    })\n",
    "\n",
    "    # Reset index to make the timestamp a column\n",
    "    plot_df = plot_df.reset_index()\n",
    "\n",
    "    # Calculate MSE for the last 24 values\n",
    "    y_true = plot_df['y']\n",
    "    mse_identity = calculate_mse(y_true, plot_df['NBEATS - Identity'])\n",
    "    mse_reinv = calculate_mse(y_true, plot_df['NBEATS - Reinv'])\n",
    "    mse_smoothing = calculate_mse(y_true, plot_df['NBEATS - Smoothing'])\n",
    "\n",
    "    # Create the plot\n",
    "    p = figure(title=f\"NYISO - {zone}\", x_axis_type='datetime', x_axis_label='Timestamp [t]', y_axis_label='Load',\n",
    "               width=1200, height=600)\n",
    "\n",
    "    # Define colors for the plot lines\n",
    "    colors = Category10[len(plot_df.columns)]\n",
    "\n",
    "    # Add the true value line\n",
    "    p.line(x='ds', y='y', source=ColumnDataSource(plot_df), line_width=2, color='black', legend_label='True Value')\n",
    "\n",
    "    # Add the prediction lines with MSE in the legend\n",
    "    p.line(x='ds', y='NBEATS - Identity', source=ColumnDataSource(plot_df), line_width=2, color=colors[0],\n",
    "           legend_label=f\"NBEATS - Identity (MSE: {mse_identity:.2f})\")\n",
    "    p.line(x='ds', y='NBEATS - Reinv', source=ColumnDataSource(plot_df), line_width=2, color=colors[1],\n",
    "           legend_label=f\"NBEATS - Reinv (MSE: {mse_reinv:.2f})\")\n",
    "    p.line(x='ds', y='NBEATS - Smoothing', source=ColumnDataSource(plot_df), line_width=2, color=colors[2],\n",
    "           legend_label=f\"NBEATS - Smoothing (MSE: {mse_smoothing:.2f})\")\n",
    "\n",
    "    # Legend formatting\n",
    "    p.legend.title = ''\n",
    "    p.legend.title_text_font_size = '12pt'\n",
    "    p.legend.label_text_font_size = '10pt'\n",
    "    p.legend.location = 'top_left'\n",
    "\n",
    "    # X-axis date formatting\n",
    "    p.xaxis.formatter = DatetimeTickFormatter(\n",
    "        days=\"%Y-%m-%d\",\n",
    "        months=\"%Y-%m-%d\",\n",
    "        years=\"%Y-%m-%d\"\n",
    "    )\n",
    "\n",
    "    return p"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Overall MSE"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "with open('all_prediction_dfs.pkl', 'rb') as f:\n",
    "    all_prediction_dfs = pickle.load(f)\n",
    "\n",
    "results = pd.DataFrame({zone: calculate_overall_mse(zone_dfs) for zone, zone_dfs in all_prediction_dfs.items()})\n",
    "\n",
    "results"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Residual Boxplot"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "def prepare_data(zone):\n",
    "    # Filter out empty DataFrames\n",
    "    valid_dfs = [df for df in all_prediction_dfs[zone] if not df.empty]\n",
    "\n",
    "    if not valid_dfs:  # If no valid DataFrames, return an empty DataFrame\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Concatenate all valid DataFrames in the list for the given zone\n",
    "    df = pd.concat(valid_dfs, ignore_index=True)\n",
    "\n",
    "    # Rename 'NBEATS1' to 'NBEATS - Reinv'\n",
    "    df = df.rename(columns={'NBEATS1': 'NBEATS - Reinv'})\n",
    "\n",
    "    # Calculate residuals for each prediction model\n",
    "    residuals = {}\n",
    "    prediction_cols = ['NBEATS - Identity', 'NBEATS - Reinv', 'NBEATS - Smoothing']\n",
    "\n",
    "    for col in prediction_cols:\n",
    "        if col in df.columns:\n",
    "            residuals[col] = df['y'] - df[col]\n",
    "        else:\n",
    "            residuals[col] = pd.Series([np.nan] * len(df))\n",
    "\n",
    "    # Convert the residuals dictionary to a DataFrame and melt it for plotting\n",
    "    residuals_df = pd.DataFrame(residuals)\n",
    "    residuals_df = residuals_df.melt(var_name='Model', value_name='Residuals')\n",
    "\n",
    "    return residuals_df.dropna()\n",
    "\n",
    "\n",
    "# Prepare data for all zones and handle empty data\n",
    "zones = list(all_prediction_dfs.keys())\n",
    "zone_data = {zone: prepare_data(zone) for zone in zones if not prepare_data(zone).empty}\n",
    "\n",
    "\n",
    "# Function to create the plot using Plotly\n",
    "def create_plot(selected_zone):\n",
    "    fig = px.box(zone_data[selected_zone], x='Model', y='Residuals',\n",
    "                 title=f'Residuals Distribution for {selected_zone}')\n",
    "    fig.update_layout(\n",
    "        width=1200,  # Adjust width as needed\n",
    "        height=700  # Adjust height as needed\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Function to update the plot based on dropdown selection\n",
    "def update_plot(change):\n",
    "    selected_zone = dropdown_zone.value\n",
    "    with output_widget:\n",
    "        clear_output(wait=True)\n",
    "        fig = create_plot(selected_zone)\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "# Dropdown widget for zone selection\n",
    "dropdown_zone = widgets.Dropdown(\n",
    "    options=zones,\n",
    "    value=zones[0],\n",
    "    description='Select Zone:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Output widget to display the plot\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# Observe changes in the dropdown\n",
    "dropdown_zone.observe(update_plot, names='value')\n",
    "\n",
    "# Initial display\n",
    "display(dropdown_zone, output_widget)\n",
    "\n",
    "# Display the initial plot\n",
    "with output_widget:\n",
    "    fig = create_plot(zones[0])\n",
    "    fig.show()\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Prediction"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "output_notebook()\n",
    "\n",
    "zones = list(all_prediction_dfs.keys())\n",
    "initial_zone = zones[0]\n",
    "initial_sample_index = 0\n",
    "\n",
    "output_prediction = widgets.Output()\n",
    "\n",
    "\n",
    "def update_plot(change=None):\n",
    "    selected_zone = dropdown_zone.value\n",
    "    selected_sample_index = dropdown_sample_index.value\n",
    "\n",
    "    # Update prediction plot\n",
    "    with output_prediction:\n",
    "        clear_output(wait=True)\n",
    "        plot_df = all_prediction_dfs[selected_zone][selected_sample_index].drop(\"ds\", axis=1).iloc[-168:].drop(\n",
    "            \"unique_id\", axis=1)\n",
    "        fig_prediction = plot_prediction(plot_df, selected_zone)\n",
    "        show(fig_prediction, notebook_handle=True)\n",
    "\n",
    "\n",
    "# Dropdown for selecting zone\n",
    "dropdown_zone = widgets.Dropdown(\n",
    "    options=zones,\n",
    "    value=initial_zone,\n",
    "    description='Select Zone:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "dropdown_zone.observe(update_plot, names='value')\n",
    "\n",
    "# Dropdown for selecting sample index\n",
    "sample_indices = list(range(len(all_prediction_dfs[initial_zone])))\n",
    "dropdown_sample_index = widgets.Dropdown(\n",
    "    options=sample_indices,\n",
    "    value=initial_sample_index,\n",
    "    description='Select Sample Index:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "dropdown_sample_index.observe(update_plot, names='value')\n",
    "\n",
    "layout = widgets.VBox([dropdown_zone, dropdown_sample_index, output_prediction])\n",
    "display(layout)\n",
    "update_plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts-scaler",
   "language": "python",
   "name": "ts-scaler"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
